{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Importing the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T05:55:32.103959Z","iopub.status.busy":"2023-03-26T05:55:32.103617Z","iopub.status.idle":"2023-03-26T05:55:37.562933Z","shell.execute_reply":"2023-03-26T05:55:37.561858Z","shell.execute_reply.started":"2023-03-26T05:55:32.103869Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, SimpleRNN\n","from keras.models import Model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T05:55:37.566468Z","iopub.status.busy":"2023-03-26T05:55:37.565457Z","iopub.status.idle":"2023-03-26T05:55:37.612216Z","shell.execute_reply":"2023-03-26T05:55:37.610541Z","shell.execute_reply.started":"2023-03-26T05:55:37.566428Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Questions</th>\n","      <th>BloomsTaxClass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Given is an array after the first partition of...</td>\n","      <td>remember</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How many steps are required to solve Tower of ...</td>\n","      <td>remember</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How many comparisons are required to find elem...</td>\n","      <td>remember</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Given an array A[-3:4, 6:10], Find the address...</td>\n","      <td>remember</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Consider the following list of 10 numbers: 35,...</td>\n","      <td>apply , remember</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>748</th>\n","      <td>Find out the names of all American actors abov...</td>\n","      <td>evaluate</td>\n","    </tr>\n","    <tr>\n","      <th>749</th>\n","      <td>Retrieve the name of each actor together with ...</td>\n","      <td>apply</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>Retrieve details of all films that were releas...</td>\n","      <td>apply</td>\n","    </tr>\n","    <tr>\n","      <th>751</th>\n","      <td>Find out the names of all actors that have pla...</td>\n","      <td>evaluate</td>\n","    </tr>\n","    <tr>\n","      <th>752</th>\n","      <td>How GROUP BY clause works? What is the differe...</td>\n","      <td>remember</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>753 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                             Questions    BloomsTaxClass\n","0    Given is an array after the first partition of...          remember\n","1    How many steps are required to solve Tower of ...          remember\n","2    How many comparisons are required to find elem...          remember\n","3    Given an array A[-3:4, 6:10], Find the address...          remember\n","4    Consider the following list of 10 numbers: 35,...  apply , remember\n","..                                                 ...               ...\n","748  Find out the names of all American actors abov...          evaluate\n","749  Retrieve the name of each actor together with ...             apply\n","750  Retrieve details of all films that were releas...             apply\n","751  Find out the names of all actors that have pla...          evaluate\n","752  How GROUP BY clause works? What is the differe...          remember\n","\n","[753 rows x 2 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"/kaggle/input/questionanalyserdataset/QuestionAnalyserDataset.csv\")\n","df = df[['Questions','BloomsTaxClass']]\n","df"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenizing the words in the Dataframe"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T05:55:37.614205Z","iopub.status.busy":"2023-03-26T05:55:37.613685Z","iopub.status.idle":"2023-03-26T05:55:37.673374Z","shell.execute_reply":"2023-03-26T05:55:37.672482Z","shell.execute_reply.started":"2023-03-26T05:55:37.614154Z"},"trusted":true},"outputs":[],"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(df['Questions'])\n","sequences = tokenizer.texts_to_sequences(df['Questions'])\n","max_len = max([len(seq) for seq in sequences])\n","padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df['BloomsTaxClass'])\n","vocab_size = len(tokenizer.word_index) + 1"]},{"cell_type":"markdown","metadata":{},"source":["## Spliting the data into training and testing sets"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T05:55:37.677092Z","iopub.status.busy":"2023-03-26T05:55:37.676677Z","iopub.status.idle":"2023-03-26T05:55:37.684259Z","shell.execute_reply":"2023-03-26T05:55:37.683269Z","shell.execute_reply.started":"2023-03-26T05:55:37.677052Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'numpy.ndarray'>\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n","print(type(X_train))"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the model architecture\n","Note that Here I have used the Bidirectional LSTM model *(As this topic is similar to Sentiment analysis)* "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T05:55:37.686800Z","iopub.status.busy":"2023-03-26T05:55:37.685988Z","iopub.status.idle":"2023-03-26T05:55:40.494000Z","shell.execute_reply":"2023-03-26T05:55:40.492962Z","shell.execute_reply.started":"2023-03-26T05:55:37.686761Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 203)]             0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 203, 128)          306432    \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 256)               263168    \n","_________________________________________________________________\n","dense (Dense)                (None, 50)                12850     \n","=================================================================\n","Total params: 582,450\n","Trainable params: 582,450\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inputs = Input(shape=(max_len,))\n","x = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n","x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(x)\n","outputs = Dense(50, activation='softmax')(x)\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T05:55:40.495693Z","iopub.status.busy":"2023-03-26T05:55:40.495345Z","iopub.status.idle":"2023-03-26T06:10:06.273320Z","shell.execute_reply":"2023-03-26T06:10:06.272199Z","shell.execute_reply.started":"2023-03-26T05:55:40.495656Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","10/10 [==============================] - 22s 2s/step - loss: 3.6411 - accuracy: 0.1944 - val_loss: 2.7477 - val_accuracy: 0.1921\n","Epoch 2/50\n","10/10 [==============================] - 16s 2s/step - loss: 2.5764 - accuracy: 0.1844 - val_loss: 2.5076 - val_accuracy: 0.0927\n","Epoch 3/50\n","10/10 [==============================] - 17s 2s/step - loss: 2.4755 - accuracy: 0.2159 - val_loss: 2.4776 - val_accuracy: 0.1921\n","Epoch 4/50\n","10/10 [==============================] - 16s 2s/step - loss: 2.4410 - accuracy: 0.2326 - val_loss: 2.4348 - val_accuracy: 0.1921\n","Epoch 5/50\n","10/10 [==============================] - 17s 2s/step - loss: 2.3973 - accuracy: 0.2243 - val_loss: 2.4436 - val_accuracy: 0.1921\n","Epoch 6/50\n","10/10 [==============================] - 16s 2s/step - loss: 2.3286 - accuracy: 0.2708 - val_loss: 2.3572 - val_accuracy: 0.3046\n","Epoch 7/50\n","10/10 [==============================] - 17s 2s/step - loss: 2.2167 - accuracy: 0.3156 - val_loss: 2.2620 - val_accuracy: 0.2980\n","Epoch 8/50\n","10/10 [==============================] - 16s 2s/step - loss: 2.1179 - accuracy: 0.3605 - val_loss: 2.1948 - val_accuracy: 0.3709\n","Epoch 9/50\n","10/10 [==============================] - 17s 2s/step - loss: 2.0181 - accuracy: 0.3804 - val_loss: 2.2007 - val_accuracy: 0.3377\n","Epoch 10/50\n","10/10 [==============================] - 16s 2s/step - loss: 1.9110 - accuracy: 0.4568 - val_loss: 2.1192 - val_accuracy: 0.3775\n","Epoch 11/50\n","10/10 [==============================] - 17s 2s/step - loss: 1.7531 - accuracy: 0.4452 - val_loss: 2.0587 - val_accuracy: 0.3510\n","Epoch 12/50\n","10/10 [==============================] - 16s 2s/step - loss: 1.5645 - accuracy: 0.5449 - val_loss: 2.1364 - val_accuracy: 0.3245\n","Epoch 13/50\n","10/10 [==============================] - 17s 2s/step - loss: 1.4600 - accuracy: 0.5930 - val_loss: 2.0750 - val_accuracy: 0.3974\n","Epoch 14/50\n","10/10 [==============================] - 16s 2s/step - loss: 1.3226 - accuracy: 0.6362 - val_loss: 2.0226 - val_accuracy: 0.4172\n","Epoch 15/50\n","10/10 [==============================] - 17s 2s/step - loss: 1.1243 - accuracy: 0.7043 - val_loss: 1.9847 - val_accuracy: 0.4106\n","Epoch 16/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.9908 - accuracy: 0.7143 - val_loss: 2.0146 - val_accuracy: 0.3974\n","Epoch 17/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.9025 - accuracy: 0.7741 - val_loss: 2.0555 - val_accuracy: 0.4172\n","Epoch 18/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.7719 - accuracy: 0.7957 - val_loss: 2.0841 - val_accuracy: 0.4106\n","Epoch 19/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.6805 - accuracy: 0.8206 - val_loss: 2.2122 - val_accuracy: 0.3709\n","Epoch 20/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.6087 - accuracy: 0.8405 - val_loss: 2.1816 - val_accuracy: 0.4437\n","Epoch 21/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.5505 - accuracy: 0.8571 - val_loss: 2.3279 - val_accuracy: 0.3775\n","Epoch 22/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.5077 - accuracy: 0.8688 - val_loss: 2.3219 - val_accuracy: 0.4305\n","Epoch 23/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.4600 - accuracy: 0.8704 - val_loss: 2.3644 - val_accuracy: 0.4371\n","Epoch 24/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.4302 - accuracy: 0.8837 - val_loss: 2.4718 - val_accuracy: 0.3642\n","Epoch 25/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.4092 - accuracy: 0.8970 - val_loss: 2.5213 - val_accuracy: 0.3775\n","Epoch 26/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.3854 - accuracy: 0.8987 - val_loss: 2.4761 - val_accuracy: 0.3709\n","Epoch 27/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.3414 - accuracy: 0.9003 - val_loss: 2.5704 - val_accuracy: 0.3974\n","Epoch 28/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.3422 - accuracy: 0.9003 - val_loss: 2.6480 - val_accuracy: 0.3841\n","Epoch 29/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.3007 - accuracy: 0.9219 - val_loss: 2.6931 - val_accuracy: 0.3775\n","Epoch 30/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.2728 - accuracy: 0.9336 - val_loss: 2.6780 - val_accuracy: 0.3775\n","Epoch 31/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.2949 - accuracy: 0.9186 - val_loss: 2.6749 - val_accuracy: 0.3907\n","Epoch 32/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.2682 - accuracy: 0.9286 - val_loss: 2.7190 - val_accuracy: 0.3907\n","Epoch 33/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.2359 - accuracy: 0.9319 - val_loss: 2.7212 - val_accuracy: 0.3775\n","Epoch 34/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.2426 - accuracy: 0.9435 - val_loss: 2.9947 - val_accuracy: 0.3377\n","Epoch 35/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.2732 - accuracy: 0.9269 - val_loss: 2.7633 - val_accuracy: 0.3907\n","Epoch 36/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.2274 - accuracy: 0.9485 - val_loss: 2.6273 - val_accuracy: 0.3841\n","Epoch 37/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.2085 - accuracy: 0.9402 - val_loss: 2.7617 - val_accuracy: 0.3974\n","Epoch 38/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1877 - accuracy: 0.9535 - val_loss: 2.8113 - val_accuracy: 0.3974\n","Epoch 39/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.1744 - accuracy: 0.9551 - val_loss: 2.8939 - val_accuracy: 0.3775\n","Epoch 40/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1618 - accuracy: 0.9618 - val_loss: 2.9417 - val_accuracy: 0.3510\n","Epoch 41/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.1395 - accuracy: 0.9618 - val_loss: 2.9718 - val_accuracy: 0.3775\n","Epoch 42/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1405 - accuracy: 0.9568 - val_loss: 3.1069 - val_accuracy: 0.3974\n","Epoch 43/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.1372 - accuracy: 0.9635 - val_loss: 3.0577 - val_accuracy: 0.3907\n","Epoch 44/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1368 - accuracy: 0.9635 - val_loss: 3.1203 - val_accuracy: 0.3709\n","Epoch 45/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.1345 - accuracy: 0.9635 - val_loss: 3.1117 - val_accuracy: 0.3709\n","Epoch 46/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1304 - accuracy: 0.9601 - val_loss: 3.1362 - val_accuracy: 0.3841\n","Epoch 47/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.1171 - accuracy: 0.9668 - val_loss: 3.1560 - val_accuracy: 0.3709\n","Epoch 48/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1121 - accuracy: 0.9601 - val_loss: 3.2760 - val_accuracy: 0.3510\n","Epoch 49/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.1026 - accuracy: 0.9668 - val_loss: 3.2086 - val_accuracy: 0.3974\n","Epoch 50/50\n","10/10 [==============================] - 17s 2s/step - loss: 0.1012 - accuracy: 0.9684 - val_loss: 3.2163 - val_accuracy: 0.3775\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f43181a9d10>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:06.275401Z","iopub.status.busy":"2023-03-26T06:10:06.274951Z","iopub.status.idle":"2023-03-26T06:10:06.740192Z","shell.execute_reply":"2023-03-26T06:10:06.739282Z","shell.execute_reply.started":"2023-03-26T06:10:06.275364Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 - 0s - loss: 3.2163 - accuracy: 0.3775\n","Validation accuracy: 0.37748345732688904\n"]}],"source":["score, acc = model.evaluate(X_test, y_test, verbose=2)\n","print(\"Validation accuracy:\", acc)"]},{"cell_type":"markdown","metadata":{},"source":["## Make predictions on new Data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:06.742025Z","iopub.status.busy":"2023-03-26T06:10:06.741664Z","iopub.status.idle":"2023-03-26T06:10:07.232824Z","shell.execute_reply":"2023-03-26T06:10:07.231868Z","shell.execute_reply.started":"2023-03-26T06:10:06.741989Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Remember' 'create']\n"]}],"source":["new_questions = ['What types of programming languages are vulnerable to buffer overflows?', 'Construct the Binary Search Tree using following data. Show each steps. 32, 45, 12, 11, 13, 92, 78, 66, 17, 70,98, 108. Show its Preorder, Inorder and Postorder traversing sequences.']\n","new_sequences = tokenizer.texts_to_sequences(new_questions)\n","new_padded_sequences = pad_sequences(new_sequences, maxlen=max_len, padding='post')\n","predictions = model.predict(new_padded_sequences)\n","predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n","print(predicted_labels)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Implementation using Glove"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:07.234420Z","iopub.status.busy":"2023-03-26T06:10:07.234065Z","iopub.status.idle":"2023-03-26T06:10:07.240560Z","shell.execute_reply":"2023-03-26T06:10:07.239358Z","shell.execute_reply.started":"2023-03-26T06:10:07.234384Z"},"trusted":true},"outputs":[],"source":["# Import the necessary libraries\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional\n","from keras.models import Model\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:07.245498Z","iopub.status.busy":"2023-03-26T06:10:07.244847Z","iopub.status.idle":"2023-03-26T06:10:07.249740Z","shell.execute_reply":"2023-03-26T06:10:07.248522Z","shell.execute_reply.started":"2023-03-26T06:10:07.245459Z"},"trusted":true},"outputs":[],"source":["# Load the Bloom's Taxonomy dataset\n","#df = pd.read_csv(\"QuestionAnalyserDatasetUpdated.csv\")\n","#df = df[['Questions','Blooms Taxonomy']]  "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:07.251664Z","iopub.status.busy":"2023-03-26T06:10:07.251230Z","iopub.status.idle":"2023-03-26T06:10:16.633364Z","shell.execute_reply":"2023-03-26T06:10:16.632389Z","shell.execute_reply.started":"2023-03-26T06:10:07.251587Z"},"trusted":true},"outputs":[],"source":["# Load the pre-trained GloVe embeddings\n","word_embeddings = {}\n","with open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","        word_embeddings[word] = coefs"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:16.635259Z","iopub.status.busy":"2023-03-26T06:10:16.634884Z","iopub.status.idle":"2023-03-26T06:10:16.927123Z","shell.execute_reply":"2023-03-26T06:10:16.926199Z","shell.execute_reply.started":"2023-03-26T06:10:16.635221Z"},"trusted":true},"outputs":[],"source":["# Tokenize the text and convert it to sequences\n","tokenizer = keras.preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts(df['Questions'])\n","sequences = tokenizer.texts_to_sequences(df['Questions'])\n","max_len = max([len(seq) for seq in sequences])\n","padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:16.928854Z","iopub.status.busy":"2023-03-26T06:10:16.928521Z","iopub.status.idle":"2023-03-26T06:10:16.947137Z","shell.execute_reply":"2023-03-26T06:10:16.946171Z","shell.execute_reply.started":"2023-03-26T06:10:16.928819Z"},"trusted":true},"outputs":[],"source":["# Create an embedding matrix for the pre-trained GloVe embeddings\n","embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = word_embeddings.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:16.949140Z","iopub.status.busy":"2023-03-26T06:10:16.948733Z","iopub.status.idle":"2023-03-26T06:10:16.957118Z","shell.execute_reply":"2023-03-26T06:10:16.956131Z","shell.execute_reply.started":"2023-03-26T06:10:16.949095Z"},"trusted":true},"outputs":[],"source":["# Convert the labels to numerical values\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df['BloomsTaxClass'])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:10:16.960392Z","iopub.status.busy":"2023-03-26T06:10:16.959607Z","iopub.status.idle":"2023-03-26T06:10:16.970169Z","shell.execute_reply":"2023-03-26T06:10:16.965467Z","shell.execute_reply.started":"2023-03-26T06:10:16.960295Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:34:17.473689Z","iopub.status.busy":"2023-03-26T07:34:17.473276Z","iopub.status.idle":"2023-03-26T07:34:17.731482Z","shell.execute_reply":"2023-03-26T07:34:17.730494Z","shell.execute_reply.started":"2023-03-26T07:34:17.473653Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_9 (InputLayer)         [(None, 203)]             0         \n","_________________________________________________________________\n","embedding_8 (Embedding)      (None, 203, 100)          239400    \n","_________________________________________________________________\n","bidirectional_8 (Bidirection (None, 256)               234496    \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 50)                12850     \n","=================================================================\n","Total params: 486,746\n","Trainable params: 247,346\n","Non-trainable params: 239,400\n","_________________________________________________________________\n"]}],"source":["# Define the model architecture\n","inputs = Input(shape=(max_len,))\n","x = Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding_matrix], input_length=max_len, trainable=False)(inputs)\n","x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(x)\n","outputs = Dense(50, activation='softmax')(x)\n","model = Model(inputs=inputs, outputs=outputs)\n","optimizer = keras.optimizers.Adam(learning_rate=0.005)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T08:03:28.072491Z","iopub.status.busy":"2023-03-26T08:03:28.072132Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","10/10 [==============================] - 15s 1s/step - loss: 0.0833 - accuracy: 0.9635 - val_loss: 3.0336 - val_accuracy: 0.4172\n","Epoch 2/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.0847 - accuracy: 0.9651 - val_loss: 2.9888 - val_accuracy: 0.3642\n","Epoch 3/50\n","10/10 [==============================] - 15s 1s/step - loss: 0.0963 - accuracy: 0.9635 - val_loss: 3.1971 - val_accuracy: 0.3775\n","Epoch 4/50\n","10/10 [==============================] - 15s 2s/step - loss: 0.0975 - accuracy: 0.9585 - val_loss: 3.0456 - val_accuracy: 0.3775\n","Epoch 5/50\n","10/10 [==============================] - 15s 2s/step - loss: 0.0970 - accuracy: 0.9585 - val_loss: 3.2325 - val_accuracy: 0.3907\n","Epoch 6/50\n","10/10 [==============================] - 15s 2s/step - loss: 0.0909 - accuracy: 0.9701 - val_loss: 2.9461 - val_accuracy: 0.3709\n","Epoch 7/50\n","10/10 [==============================] - 15s 1s/step - loss: 0.0944 - accuracy: 0.9668 - val_loss: 2.9180 - val_accuracy: 0.4106\n","Epoch 8/50\n","10/10 [==============================] - 15s 2s/step - loss: 0.1030 - accuracy: 0.9684 - val_loss: 2.8785 - val_accuracy: 0.3709\n","Epoch 9/50\n","10/10 [==============================] - 15s 1s/step - loss: 0.0752 - accuracy: 0.9668 - val_loss: 3.0734 - val_accuracy: 0.3775\n","Epoch 10/50\n","10/10 [==============================] - 15s 1s/step - loss: 0.0764 - accuracy: 0.9668 - val_loss: 3.2631 - val_accuracy: 0.3775\n","Epoch 11/50\n","10/10 [==============================] - 16s 2s/step - loss: 0.0969 - accuracy: 0.9635 - val_loss: 3.1418 - val_accuracy: 0.3642\n","Epoch 12/50\n"," 8/10 [=======================>......] - ETA: 2s - loss: 0.0878 - accuracy: 0.9629"]}],"source":["# Train the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:32:23.073263Z","iopub.status.busy":"2023-03-26T07:32:23.072801Z","iopub.status.idle":"2023-03-26T07:32:23.551465Z","shell.execute_reply":"2023-03-26T07:32:23.550536Z","shell.execute_reply.started":"2023-03-26T07:32:23.073228Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 - 0s - loss: 2.9013 - accuracy: 0.3974\n","Validation accuracy: 0.3973509967327118\n"]}],"source":["score, acc = model.evaluate(X_test, y_test, verbose=2)\n","print(\"Validation accuracy:\", acc)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T06:23:01.232680Z","iopub.status.busy":"2023-03-26T06:23:01.232287Z","iopub.status.idle":"2023-03-26T06:23:01.676536Z","shell.execute_reply":"2023-03-26T06:23:01.674928Z","shell.execute_reply.started":"2023-03-26T06:23:01.232640Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['remember' 'create']\n"]}],"source":["# Make predictions on new data\n","new_questions = ['What can be the maximum number of nodes in binary tree with height 4?', 'Write an algorithm to insert a node at beginning in circular linked list.']\n","new_sequences = tokenizer.texts_to_sequences(new_questions)\n","new_padded_sequences = pad_sequences(new_sequences, maxlen=max_len, padding='post')\n","predictions = model.predict(new_padded_sequences)\n","predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n","print(predicted_labels)"]},{"cell_type":"markdown","metadata":{},"source":["## FastText Implementation Trial."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import fasttext\n","from tensorflow import keras\n","from keras.layers import Input, LSTM, Dense, Bidirectional, SimpleRNN\n","from keras.models import Model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the data\n","df = pd.read_csv(\"/kaggle/input/questionanalyserdataset/QuestionAnalyserDataset.csv\")\n","df = df[['Questions','BloomsTaxClass']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tokenize the questions\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(df['Questions'])\n","sequences = tokenizer.texts_to_sequences(df['Questions'])\n","max_len = max([len(seq) for seq in sequences])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Pad the sequences to a fixed length\n","padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df['BloomsTaxClass'])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the FastText pre-trained word embeddings\n","ft_model = fasttext.load_model('cc.en.300.bin')\n","\n","# Generate word embeddings for each question in the dataset\n","embedding_dim = ft_model.get_dimension()\n","embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","for word, i in tokenizer.word_index.items():\n","    embedding_matrix[i] = ft_model[word]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the model architecture\n","inputs = Input(shape=(max_len,))\n","x = keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(inputs)\n","x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(x)\n","outputs = Dense(50, activation='softmax')(x)\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model..summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate the model\n","score, acc = model.evaluate(X_test, y_test, verbose=2)\n","print(\"Validation accuracy:\", acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use the model to make predictions on new questions\n","new_questions = ['What types of programming languages are vulnerable to buffer overflows?', 'Construct the Binary Search Tree using following data. Show each steps. 32, 45, 12, 11, 13, 92, 78, 66, 17, 70,98, 108. Show its Preorder, Inorder and Postorder traversing sequences.']\n","new_sequences = tokenizer.texts_to_sequences(new_questions)\n","new_padded_sequences = pad_sequences(new_sequences, maxlen=max_len, padding='post')\n","predictions = model.predict(new_padded_sequences)\n","predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n","print(predicted_labels)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, SimpleRNN\n","from keras.models import Model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, KFold\n","\n","# Load the data\n","df = pd.read_csv(\"QuestionAnalyserDataset.csv\")\n","df = df[['Questions','Blooms Taxonomy']]\n","\n","# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(df['Questions'])\n","sequences = tokenizer.texts_to_sequences(df['Questions'])\n","max_len = max([len(seq) for seq in sequences])\n","padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df['Blooms Taxonomy'])\n","\n","inputs = Input(shape=(max_len,))\n","x = Embedding(vocab_size, 128, input_length=max_len)(inputs)\n","x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(x)\n","outputs = Dense(50, activation='sigmoid')(x)\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()\n","\n","# Define k-fold cross validation\n","k = 5\n","kfold = KFold(n_splits=k, shuffle=True)\n","\n","# Perform k-fold cross validation\n","test_losses = []\n","test_accuracies = []\n","for i, (train_idx, test_idx) in enumerate(kfold.split(padded_sequences)):\n","    X_train, X_test = padded_sequences[train_idx], padded_sequences[test_idx]\n","    y_train, y_test = labels[train_idx], labels[test_idx]\n","\n","    # Compile the model\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    # Train the model\n","    print('Fold:', i+1)\n","    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64, verbose=1)\n","\n","    # Evaluate the model on the test set\n","    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n","    test_losses.append(test_loss)\n","    test_accuracies.append(test_acc)\n","\n","# Print the average test loss and accuracy across all folds\n","print('Average test loss:', np.mean(test_losses))\n","print('Average test accuracy:', np.mean(test_accuracies))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
